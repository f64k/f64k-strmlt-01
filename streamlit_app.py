import os, re, sys, time, math, shutil, urllib, string, random, pickle, zipfile, datetime
import streamlit as st, pandas as pd, numpy as np
import my_static_methods as my_stm

st.html(my_stm.STYLE_CORRECTION)

REPO = my_stm.HfRepo("f64k/gaziev", "dataset", st.secrets["HF_WRITE"])
lstRepoFiles = my_stm.list_files_hf(REPO) # —Å–ø–∏—Å–æ–∫ —É–∂–µ –∏–º–µ—é—â–∏—Ö—Å—è –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ —Ñ–∞–π–ª–æ–≤
dictTestFilesIdXyz = {f.upper().replace("ID_XYZ/",""): f.upper() for f in lstRepoFiles if f.upper().startswith("ID_XYZ/")}

@st.cache_data
def GetListOf_XYZV_ToTrainClassifier(repo):
    lstRepoZipFiles = ["TrainData_1504_AB_gaziev.zip","TestData_1504_AB_gaziev.zip","TestData3_2204_noAB_gaziev.zip"]
    dictTrainThreeDataframes = my_stm.load_dataframes_from_hf(REPO, lstRepoZipFiles)
    lstDfOriginal = [my_stm.df_process_v_column(df) for df in dictTrainThreeDataframes.values()]
    return lstDfOriginal

def ReRun() :
    try: st.rerun()
    except: pass

def DescriptionMarkdown() -> str:
    return """
        ## –û–ø–∏—Å–∞–Ω–∏–µ
        ### 1) –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        –ò—Å—Ç–æ—á–Ω–∏–∫–æ–º –¥–∞–Ω–Ω—ã—Ö —è–≤–ª—è–µ—Ç—Å—è —Ñ–∞–π–ª CSV. –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ ID;X;Y;Z\n
        ### –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–±–æ—Ç—ã (–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è)
        –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–∞–Ω–Ω—ã–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —ç—Ç–æ —Å—Ç—Ä–æ–∫–∏ —Ü–∏—Ñ—Ä (—Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö ¬´;¬ª), –Ω–æ —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.\n
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–æ–ª–∂–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏, –ø—Ä–∏ —ç—Ç–æ–º —Å–µ—Ä–≤–∏—Å –æ–±—è–∑–∞–Ω –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –Ω–µ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç –∏—Ö –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É.\n
        –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Ç–∞–∫–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç—Å—è –≤–æ –≤–Ω–µ—à–Ω–µ–º —Ñ–∞–π–ª–µ .csv \n
        –ü—Ä–∏ —ç—Ç–æ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ –¥–æ 500 ¬´–ø–∞–∫–µ—Ç–æ–≤¬ª (—Å—Ç—Ä–æ–∫ —Ü–∏—Ñ—Ä –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–ª—è –µ–¥–∏–Ω–æ—Ä–∞–∑–æ–≤–æ–π –æ—Ç—Ä–∞–±–æ—Ç–∫–∏ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é) –¥–∞–Ω–Ω—ã—Ö, –∞ —Ç–∞–∫–∂–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞.\n
        –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, –±—É–¥–µ—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞ (–∑–∞–¥–∞–Ω–∏—è).\n
        –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ ‚Äì csv.\n
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –¥–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–∞–∑ –≤ –¥–µ–Ω—å.\n
        –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞ (–∑–∞–¥–∞–Ω–∏—è) –Ω–µ –±–æ–ª–µ–µ 1 –º–∏–Ω—É—Ç—ã\n
    """

def save_dataframe_nodialog_idxyz(new_filename, dfToSave):
    commit_info = my_stm.save_dataframe_to_hf(REPO, dfToSave, new_filename, "ID_XYZ")
    st.toast(commit_info, icon='üÜï')
    ReRun()

#st.sidebar.markdown("üßä –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –ø–∞–∫–µ—Ç–∞–º XYZ")

with st.container():
    cols1 = st.columns([1,12]) # vertical_alignment: "center"
    cols1[0].popover("‚ùì", help="–ø–æ—è—Å–Ω–µ–Ω–∏—è").markdown(DescriptionMarkdown())
    cols1[1].info("üîÆ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ –ø–∞–∫–µ—Ç–∞–º ID_XYZ. üìú —Ñ–æ—Ä–º–∞—Ç CSV. üßä –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ ID;X;Y;Z. üìê —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–æ–≤ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π.")

#col1, col2 = st.columns([2,5])
col1, col2 = st.columns([4,2])

with col1.popover("üÜï –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π —Ñ–∞–π–ª", use_container_width=False):
    uploaded_file = st.file_uploader("üíæ ‚Äú–æ—Ç–∫—Ä–æ–π—Ç–µ CSV –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏‚Äù", ["csv"])
    if uploaded_file is not None:
        dfLoaded = None
        delim = ";"
        enc = "utf-8"
        if uploaded_file.type == "text/csv":
            try: dfLoaded = pd.read_csv(uploaded_file, sep=delim, encoding=enc)
            except Exception as ex: st.write(ex)
        else:
            if uploaded_file.type == "application/x-zip-compressed":
                try: dfLoaded = pd.read_csv(uploaded_file, sep=delim, encoding=enc, compression="zip")
                except Exception as ex: st.write(ex)
            else:
                st.error(uploaded_file.type)
        # dataframe ready. try to upload to HF
        if not dfLoaded is None:
            dfToUpload = dfLoaded
            if "ID" in dfToUpload.columns:
                dfToUpload = dfLoaded.query("ID!='ID'")
            #col2.dataframe(df)
            colnames = "".join(dfToUpload.columns)
            if colnames.upper().startswith("IDXYZ"):
                dgID = dfToUpload.groupby("ID") # , include_groups=False
                dictGroupID = dict(list(dgID))
                lstGroupIDs = list(dictGroupID.keys())
                #col2.write(dictGroupID)
                lst_len = list(set(dgID.apply(len)))
                if len(lst_len) == 1:
                    fileXYZ = f"{colnames}_{len(dictGroupID)}x{lst_len[0]}_{lstGroupIDs[0]}_{lstGroupIDs[-1]}.csv".upper()
                    if fileXYZ in dictTestFilesIdXyz.keys():
                        if st.button(f"—Ç–∞–∫–æ–π —Ñ–∞–π–ª –µ—Å—Ç—å! –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Ñ–∞–π–ª '{fileXYZ}'?"):
                            save_dataframe_nodialog_idxyz(fileXYZ, dfToUpload)
                    else:
                        save_dataframe_nodialog_idxyz(fileXYZ, dfToUpload)
                else:
                    st.error(f"–†–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –ø–∞–∫–µ—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö ID, –≤–∞—Ä–∏–∞–Ω—Ç—ã : {lst_len}")
            else:
                st.error(f"–°—Ç–æ–ª–±—Ü—ã –Ω–µ ID;X;Y;Z ! –ù–∞–±–ª—é–¥–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã : {colnames}")

# —Å–ø–∏—Å–æ–∫ —É–∂–µ –∏–º–µ—é—â–∏—Ö—Å—è –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ —Ñ–∞–π–ª–æ–≤. –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ —á—Ç–µ–Ω–∏–µ
lstRepoFiles = my_stm.list_files_hf(REPO)
dictTestFilesIdXyz = {f.upper().replace("ID_XYZ/",""): f.upper() for f in lstRepoFiles if f.upper().startswith("ID_XYZ/")}
selectedFile = col1.radio("üì∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –ø–∞–∫–µ—Ç—ã", dictTestFilesIdXyz.keys(), index=None)

# –≤—ã–±—Ä–∞–Ω —Ñ–∞–π–ª –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
if selectedFile is not None:
    dict_ONE_IDXYZ = my_stm.load_dataframes_from_hf(REPO, [dictTestFilesIdXyz[selectedFile]])
    if len(dict_ONE_IDXYZ) > 0:
        df_idxyz = list(dict_ONE_IDXYZ.values())[0]
        dfShow = df_idxyz
        dgID = df_idxyz.groupby("ID") # , include_groups=False
        dictGroupID = dict(list(dgID))
        dfShow = dgID.apply(len).reset_index()
        #col1.dataframe(dfShow, height=400)
        pack_size = list(set(dgID.apply(len)))[0]
        lstDfOriginal = GetListOf_XYZV_ToTrainClassifier(REPO)
        classifier_object, df_train_with_predict, time_elapsed = my_stm.GetClassifier(lstDfOriginal, pack_size-1)
        col2.popover(type(classifier_object).__name__).write(type(classifier_object))
        # –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ
        columns_xyzv = [c for c in df_train_with_predict.columns if "Vis" in c] + [c for c in df_train_with_predict.columns if c[0] in "XYZ"]
        #col2.dataframe(df_train_with_predict[columns_xyzv], height=650)
        # —Ä–∞—Å—á–µ—Ç –ø–∞–∫–µ—Ç–æ–≤
        xyz = ["X","Y","Z"]
        df_packs_reshaped = dgID.apply(lambda df: pd.Series(df[xyz].values[::-1].reshape(1,-1)[0])).reset_index()
        x_test_vect = df_packs_reshaped.iloc[:,1:]
        df_packs_reshaped["–ü—Ä–æ–≥–Ω–æ–∑_V"] = classifier_object.predict(x_test_vect.values)
        col2.dataframe(df_packs_reshaped[["ID","–ü—Ä–æ–≥–Ω–æ–∑_V"]], height=620)
        # –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        # col2.write(st.session_state)


